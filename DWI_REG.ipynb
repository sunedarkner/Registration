{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from time import time\n",
    "\n",
    "def CubicBSpline3D(pts,x,device='cpu',scale=[1.0, 1.0, 1.0],return_jac=False):\n",
    "    scale=torch.tensor(scale,dtype=torch.float32,device=device)\n",
    "    \n",
    "    t_idx=pts.mul(1/scale).floor()\n",
    "    #t_idx.detach()\n",
    "    p=torch.arange(pts.size(0))\n",
    "    #print(p)\n",
    "    t=pts.mul(1/scale)-t_idx\n",
    "    #t_idx=torch.tensor(_idx.clone().flatten(),dtype=torch.int32,device=device)\n",
    "    ones4=torch.ones([4,4,4],dtype=torch.int32,device=device)\n",
    "    onesp=torch.ones(t.size(0),dtype=torch.int32,device=device)\n",
    "    t_idx=t_idx.flatten()\n",
    "    #print(t_idx)\n",
    "    stride_x, stride_y, stride_z=torch.meshgrid([torch.arange(0,4,device=device)-2, torch.arange(0,4,device=device)-2, torch.arange(0,4,device=device)-2])\n",
    "    indices1=torch.clamp(torch.einsum('a,bcd->abcd',t_idx[3*p],ones4)+torch.einsum('a,bcd->abcd',onesp,stride_x.int()),0,x.shape[1]-1)*(x.shape[2]*x.shape[3])\n",
    "    #print(indices.shape)\n",
    "    indices2=torch.clamp(torch.einsum('a,bcd->abcd',t_idx[3*p+1],ones4)+torch.einsum('a,bcd->abcd',onesp,stride_y.int()),0,x.shape[2]-1)*(x.shape[3])\n",
    "    #print(indices.shape)\n",
    "    indices3=torch.clamp(torch.einsum('a,bcd->abcd',t_idx[3*p+2],ones4)+torch.einsum('a,bcd->abcd',onesp,stride_z.int()),0,x.shape[3]-1)\n",
    "    #print(indices.shape)\n",
    "    indices=indices1.long()+indices2.long()+indices3.long()\n",
    "    indices=indices.long()\n",
    "    \n",
    "    jac=None\n",
    "    a=torch.stack([t.flatten()*0+1, t.flatten(), t.flatten()**2, t.flatten()**3],dim=1) \n",
    "    b=torch.tensor(([1, 4, 1, 0],[-3, 0, 3, 0],[3, -6, 3, 0],[-1, 3, -3, 1]),dtype=torch.float32,device=device)/6 \n",
    "    y=torch.mm(a,b)\n",
    "    w=torch.sum(torch.einsum('ab,ac,ad->abcd',y[3*p,:],y[3*p+1,:],y[3*p+2,:])*x.flatten(start_dim=1)[:,indices.long()],dim=[2,3,4])\n",
    "    #print(w)\n",
    "    if(return_jac):\n",
    "        da=torch.stack([t.flatten()*0, t.flatten()*0+1, t.flatten()*2, 3*t.flatten()**2],dim=1) \n",
    "        dy=torch.mm(da,b)\n",
    "        wx=torch.sum(torch.einsum('ab,ac,ad->abcd',dy[3*p,:],y[3*p+1,:],y[3*p+2,:])*x.flatten(start_dim=1)[:,indices],dim=[2,3,4])\n",
    "        wy=torch.sum(torch.einsum('ab,ac,ad->abcd',y[3*p,:],dy[3*p+1,:],y[3*p+2,:])*x.flatten(start_dim=1)[:,indices],dim=[2,3,4])\n",
    "        wz=torch.sum(torch.einsum('ab,ac,ad->abcd',y[3*p,:],y[3*p+1,:],dy[3*p+2,:])*x.flatten(start_dim=1)[:,indices],dim=[2,3,4])\n",
    "        jac=torch.stack([wx.t()/scale[0],wy.t()/scale[0],wz.t()/scale[0]],dim=2)\n",
    "    return w,jac\n",
    " \n",
    "\n",
    "def NMI(x,device):\n",
    "    h1,h2,h3=Histogram2D(x,device)\n",
    "    p1=h1/h1.sum()\n",
    "    p2=h2/h2.sum()\n",
    "    p3=h3/h3.sum()\n",
    "    HIJ=-torch.sum(p1*torch.log(p1))\n",
    "    HI=-torch.sum(p2*torch.log(p2))\n",
    "    HJ=-torch.sum(p3*torch.log(p3))\n",
    "    #print(HIJ,HI,HJ,p1.sum(),p2.sum(),p3.sum())\n",
    "    return(HI+HJ)/HIJ\n",
    "\n",
    "class affine_registration:\n",
    "    def __init__(self,img_s,img_t):\n",
    "        self.img_t=img_t\n",
    "        self.img_t=img_s\n",
    "        self.resolution_s=img_s.get_header().get_zooms()\n",
    "        self.resolution_t=img_t.get_header().get_zooms()\n",
    "        \n",
    "def createStencil3D(device='cpu'):  \n",
    "    stencil3D=torch.tensor([[1,0,0],#basis x,y,z\n",
    "                         [0,1,0],\n",
    "                         [-1,0,0],\n",
    "                         [0,-1,0],\n",
    "                          [0,0,1],\n",
    "                         [0,0,-1],\n",
    "                          [1,1,0],# xy\n",
    "                         [-1,1,0],\n",
    "                         [1,-1,0],\n",
    "                         [-1,-1,0],\n",
    "                         [1,0,1], #xz\n",
    "                         [-1,0,1],\n",
    "                         [1,0,-1],\n",
    "                         [-1,0,-1],\n",
    "                         [0,1,1], #yz\n",
    "                         [0,-1,1],\n",
    "                         [0,1,-1],\n",
    "                         [0,-1,-1],\n",
    "                          [1,1,1], #xyz\n",
    "                         [-1,1,1],\n",
    "                         [1,1,-1],\n",
    "                         [-1,1,-1],\n",
    "                          [1,-1,1], #xyz\n",
    "                         [-1,-1,1],\n",
    "                         [1,-1,-1],\n",
    "                         [-1,-1,-1],\n",
    "                         ],dtype=torch.float32,device=device).t()\n",
    "    q=torch.norm(stencil3D,p=2,dim=0)\n",
    "    stencil3D.div_(torch.stack([q,q,q],dim=0)).t()\n",
    "    return stencil3D       \n",
    "def Histogram2D(vals,device):\n",
    "    rangeh=torch.ceil(vals.max()-vals.min()).long()+4\n",
    "    t_idx=vals.floor().long()+2\n",
    "    p=torch.arange(vals.size(0))\n",
    "    t=vals.double()+2-t_idx\n",
    "    #print(\"rangeh: \",rangeh, '\\n')\n",
    "    ones4=torch.ones([2,2],dtype=torch.int32,device=device)\n",
    "    onesp=torch.ones(t.size(0),dtype=torch.int32,device=device)\n",
    "    stride_x, stride_y=torch.meshgrid([torch.arange(0,2,device=device)-1, torch.arange(0,2,device=device)-1])\n",
    "    t_idx=t_idx.flatten()\n",
    "    indices=torch.einsum('a,bc->abc',t_idx[2*p],ones4)*(rangeh)\n",
    "    indices+=torch.einsum('a,bc->abc',onesp,stride_x)*rangeh\n",
    "    indices+=torch.einsum('a,bc->abc',t_idx[2*p+1],ones4)\n",
    "    indices+=torch.einsum('a,bc->abc',onesp,stride_y)\n",
    "    y=torch.stack([1-t.flatten(), t.flatten()],dim=1)\n",
    "    \n",
    "    res=(torch.einsum('ab,ac->abc',y[2*p,:],y[2*p+1,:]))\n",
    "   # print(\"res: \",res.sum(),res.shape,indices.shape)\n",
    "    sort_res,nid=torch.sort(indices.flatten())\n",
    "    nres=res.flatten()[nid.flatten()]\n",
    "    v,ids=sort_res.flatten().unique_consecutive(return_counts=True)\n",
    "    val=torch.split(nres.flatten(),ids.tolist());\n",
    "    hist=torch.zeros(v.size(),device=device,dtype=torch.float32)\n",
    "    for index, value in enumerate(val): \n",
    "        hist[index]=value.sum()\n",
    "    \n",
    "    sort_res,nid=torch.sort(v.flatten()%rangeh)\n",
    "    nres=hist.flatten()[nid.flatten()]\n",
    "    va,ids=sort_res.flatten().unique_consecutive(return_counts=True)\n",
    "    vala=torch.split(nres.flatten(),ids.tolist());\n",
    "    hist_a=torch.zeros(va.size(),device=device,dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for index, value in enumerate(vala): \n",
    "        hist_a[index]=value.sum()\n",
    "    sort_res,nid=torch.sort((v.flatten()/rangeh).int())\n",
    "    nres=hist.flatten()[nid.flatten()]\n",
    "    vb,ids=sort_res.flatten().unique_consecutive(return_counts=True)\n",
    "    valb=torch.split(nres.flatten(),ids.tolist());\n",
    "    hist_b=torch.zeros(vb.size(),device=device,dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for index, value in enumerate(valb): \n",
    "        hist_b[index]=value.sum()\n",
    "    return hist[hist>0], hist_a[hist_a>0], hist_b[hist_b>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (145, 174, 145, 90) (145, 174, 145)\n",
      "data.shape (145, 174, 145, 90) (145, 174, 145)\n"
     ]
    }
   ],
   "source": [
    "#this will load the data in the requird format for the registration\n",
    "\n",
    "import numpy as np\n",
    "device='cpu'\n",
    "#dipy.io.image is for loading / saving imaging datasets dipy.io.gradients is for loading / saving our bvals and bvecs\n",
    "\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "#from dipy.core.gradients import gradient_table\n",
    "#dipy.reconst is for the reconstruction algorithms which we use to create voxel models from the raw data.\n",
    "\n",
    "\n",
    "\n",
    "from dipy.data import get_fnames\n",
    "import os\n",
    "\n",
    "# load data 1\n",
    "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames('stanford_hardi')\n",
    "#Next, we read the saved dataset. gtab contains a GradientTable object (information about the gradients e.g. b-values and b-vectors).\n",
    "\n",
    "#the path to the data of the reference\n",
    "path='D://HCP//HCP//100206//T1w//Diffusion//'\n",
    "hardi_bval_fname=path+'bvals'\n",
    "hardi_bvec_fname=path+'bvecs'\n",
    "hardi_fname=path+'data.nii.gz'\n",
    "hardi_mask_fname=path+'nodif_brain_mask.nii.gz'\n",
    "\n",
    "data, affine = load_nifti(hardi_fname)\n",
    "maskdata, maffine = load_nifti(hardi_mask_fname)\n",
    "mdata=np.repeat(maskdata.reshape([1,145, 174, 145]),288,axis=0)\n",
    "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "\n",
    "#selecting b=1000\n",
    "res= (0 < np.round(bvals/100)*100) * (np.round(bvals/100)*100 < 1500)\n",
    "res_m= (10 > np.round(bvals/100)*100) \n",
    "bvals=np.round(bvals[res]/100)*100\n",
    "\n",
    "bvecs=bvecs[res,:]\n",
    "mdata=mdata[res,:,:,:]\n",
    "\n",
    "#normalizing with b0\n",
    "td=data[:,:,:,res_m].mean(3)\n",
    "data=data[:,:,:,res]/(td[:,:,:,None]+1e-4)\n",
    "\n",
    "#formatting the data to our specification\n",
    "data1f=torch.tensor(data).permute([3,0,1,2])\n",
    "nbvecs1=torch.tensor(bvecs)\n",
    "\n",
    "#the path to the data of the target\n",
    "path='D://HCP//HCP//100307//T1w//Diffusion//'\n",
    "hardi_bval_fname=path+'bvals'\n",
    "hardi_bvec_fname=path+'bvecs'\n",
    "hardi_fname=path+'data.nii.gz'\n",
    "hardi_mask_fname=path+'nodif_brain_mask.nii.gz'\n",
    "\n",
    "data, affine = load_nifti(hardi_fname)\n",
    "maskdata, maffine = load_nifti(hardi_mask_fname)\n",
    "mdata=np.repeat(maskdata.reshape([1,145, 174, 145]),288,axis=0)\n",
    "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "\n",
    "#selecting b=1000\n",
    "res= (0 < np.round(bvals/100)*100) * (np.round(bvals/100)*100 < 1500)\n",
    "res_m= (10 > np.round(bvals/100)*100) \n",
    "bvals=np.round(bvals[res]/100)*100\n",
    "bvecs=bvecs[res,:]\n",
    "\n",
    "normalizing with b0\n",
    "mdata=mdata[res,:,:,:]\n",
    "td=data[:,:,:,res_m].mean(3)\n",
    "data=data[:,:,:,res]/(td[:,:,:,None]+1e-4)\n",
    "\n",
    "#formatting the data to our specification\n",
    "data2f=torch.tensor(data).permute([3,0,1,2])\n",
    "nbvecs2=torch.tensor(bvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0543, grad_fn=<NegBackward>) 17.32465171813965\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cde9b6b3ab53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m#compute dis-similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mcst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mNMI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mcst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import torch.optim as optim\n",
    "\n",
    "#setting the concentration parameter of the watson kernel\n",
    "kappa = 10\n",
    "\n",
    "#define the evaluation points\n",
    "s_x, s_y, s_z=(torch.meshgrid([torch.arange(0,70,device=device), torch.arange(0,90,device=device), torch.arange(0,70,device=device)]))\n",
    "pts=(torch.stack([s_x.flatten(),s_y.flatten()+5,s_z.flatten()],dim=1).float()+2.25)*3\n",
    "\n",
    "#define the computational grid\n",
    "x=torch.rand([3, 60, 60, 60], dtype=torch.float32, requires_grad=True,device=device)\n",
    "\n",
    "#reduce the pointset with a mask\n",
    "\n",
    "\n",
    "#evaluate the target image\n",
    "ref,_=CubicBSpline3D(pts,data1f,device,[1,1,1])\n",
    "\n",
    "#create DWI evaluation orientations\n",
    "stencil=createStencil3D(device)\n",
    "\n",
    "#create identity matrices for jacobian computations\n",
    "lid = torch.eye(3)\n",
    "lid = lid.reshape((1, 3, 3))\n",
    "Id = lid.repeat(pts.shape[0], 1, 1).to(device)\n",
    "\n",
    "#perform watson interpolation over the stencil for all evaluation points\n",
    "watson_w=kappa*torch.einsum('abc,eb->ace',(torch.nn.functional.normalize(torch.einsum('abc,cd->abd',Id,stencil),2,dim=1)),nbvecs1.float())**2\n",
    "#normalizing using a trick to avoid overflow\n",
    "watson_w=torch.exp(watson_w-(watson_w.max(dim=2))[0][:,:,None])\n",
    "watson_w=watson_w/(watson_w.sum(dim=2)[:,:,None])\n",
    "ref=torch.einsum('abc,ca->ab',watson_w,ref)\n",
    "\n",
    "#initialize optimizer\n",
    "no_iter=200\n",
    "lr=1\n",
    "optimizer = optim.Adam([x], lr=lr)\n",
    "for i in range(no_iter):\n",
    " \n",
    "    st = time()\n",
    "    #deformation computation\n",
    "    dp,jac=CubicBSpline3D(pts,x,device,[10.0, 10.0, 10.0],True)\n",
    "    tpts=pts+dp.t()\n",
    "    \n",
    "    #interpolate image\n",
    "    mov,_=CubicBSpline3D(tpts,data2f,device,[1,1,1])\n",
    "    \n",
    "    #perform watson interpolation over the deformed stencil for all evaluation points\n",
    "    watson_w=kappa*torch.einsum('abc,eb->ace',(torch.nn.functional.normalize(torch.einsum('abc,cd->abd',jac+Id,stencil),2,dim=1)),nbvecs2.float())**2\n",
    "    #normalizing using a trick to avoid overflow\n",
    "    watson_w=torch.exp(watson_w-(watson_w.max(dim=2))[0][:,:,None])\n",
    "    watson_w=watson_w/(watson_w.sum(dim=2)[:,:,None])\n",
    "    mov=torch.einsum('abc,ca->ab',watson_w,mov)\n",
    "    \n",
    "    #prepare data for similarity computation\n",
    "    pair=torch.stack([mov.flatten(),ref.flatten()],dim=1)\n",
    "    \n",
    "    #compute dis-similarity\n",
    "    cst=-NMI(pair,device)\n",
    "    cst.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(cst,time()-st)\n",
    "    print(i)\n",
    "    optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150000, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
